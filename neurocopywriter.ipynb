{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yzhulDRbrbXY",
        "outputId": "42699d46-df60-4413-bfde-d0d7e69e884f"
      },
      "outputs": [],
      "source": [
        "# @title Подключение к Гугл Диску\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ao0sG1dzzi4X",
        "outputId": "9b065ba2-8ca7-435d-bbbe-ae6bee3fce20"
      },
      "outputs": [],
      "source": [
        "# @title Подключение whisper и youtube-dl\n",
        "!pip install git+https://github.com/ytdl-org/youtube-dl.git\n",
        "!pip install git+https://github.com/openai/whisper.git\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3GfW1TsSNBt",
        "outputId": "0ca546a6-7c9f-4e49-af06-29c2eea5d8c5"
      },
      "outputs": [],
      "source": [
        "!pip install tiktoken==0.4.0 openai==0.28.0 langchain==0.0.281 faiss-cpu==1.7.4\n",
        "!pip install -qq python-docx\n",
        "!pip install -U pytube\n",
        "from IPython.display import clear_output\n",
        "# clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vawyL4VISi1X"
      },
      "outputs": [],
      "source": [
        "# @title Устанавливаем необходимые библиотеки\n",
        "import whisper\n",
        "import os\n",
        "import gdown\n",
        "import requests\n",
        "import re\n",
        "import time\n",
        "from IPython.display import HTML, clear_output\n",
        "import subprocess\n",
        "from pathlib import Path\n",
        "import json\n",
        "from pytube import YouTube\n",
        "import tiktoken\n",
        "from docx import Document\n",
        "from docx.enum.text import WD_PARAGRAPH_ALIGNMENT\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "from tqdm.auto import tqdm\n",
        "import getpass\n",
        "import pickle\n",
        "from urllib.request import urlopen\n",
        "import openai\n",
        "import subprocess\n",
        "import codecs\n",
        "from langchain.chains import ConversationChain         # Импортируем класс для создания цепочек диалогов\n",
        "from langchain.chat_models import ChatOpenAI           # Импортируем класс для работы с чатами на базе OpenAI\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.memory import ConversationBufferMemory  # Импортируем класс для управления памятью диалогов\n",
        "from langchain.text_splitter import MarkdownHeaderTextSplitter, Document, RecursiveCharacterTextSplitter\n",
        "from langchain.schema import (\n",
        "    AIMessage,\n",
        "    HumanMessage,\n",
        "    SystemMessage\n",
        ")\n",
        "import urllib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VP0MnJW2vnu9"
      },
      "outputs": [],
      "source": [
        "# @title Здесь нужно вставить ссылку на видео на иностранном языке\n",
        "# указываем ссылку на нужное нам видео на ютуб\n",
        "yt_urls = ['https://www.youtube.com/watch?v=880TBXMuzmk&pp=ygUhR29vZ2xlIERldmVsb3BlcnMgWW91VHViZSBDaGFubmVs']\n",
        "YouTube_video_title = \"Разработчики Google о будущем искусственного интеллекта\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohoy48lRxvVe"
      },
      "source": [
        "## Получение аудио-дорожки из видео по ссылке и загрузка в колаб"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bagfigtIxzBT"
      },
      "outputs": [],
      "source": [
        "def my_mkdirs(folder):\n",
        "  if os.path.exists(folder)==False:\n",
        "    os.makedirs(folder)\n",
        "my_mkdirs('/content/')\n",
        "output_folder = '/content/drive/MyDrive/data_structure/'\n",
        "my_mkdirs(output_folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l005nXquJzr5",
        "outputId": "e92805ad-05dc-48a2-ddaa-bbf6dc40ec77"
      },
      "outputs": [],
      "source": [
        "# Получаем первую (и единственную) ссылку из списка yt_urls\n",
        "url = yt_urls[0]\n",
        "\n",
        "# Используем youtube-dl для получения имени файла, который будет сохранен\n",
        "file_name = !youtube-dl $url -f 'bestaudio[ext=m4a]' --get-filename -o 'tmp/%(title)s.m4a'\n",
        "\n",
        "# Загружаем аудио с лучшим качеством (в формате m4a)\n",
        "!youtube-dl $url -f 'bestaudio[ext=m4a]' -o 'tmp/%(title)s.m4a'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKpoC6xjpRL-",
        "outputId": "492e7642-77be-4849-f945-f2c028819dca"
      },
      "outputs": [],
      "source": [
        "!ls \"/content/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWaANKY8YUtS",
        "outputId": "70b1d1d7-c253-4aa6-cf74-f5566459b33c"
      },
      "outputs": [],
      "source": [
        "# Используем Whisper для обработки аудиофайла\n",
        "# УКАЗЫВАЕМ СВОЕ НАЗВАНИЕ ФАЙЛА .mp4!\n",
        "%%time\n",
        "!whisper \"/content/The AI revolution - Google's developers on the future of artificial intelligence _ 60 Minutes-880TBXMuzmk.mp4\" --model large"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yccq8O6BTnZz",
        "outputId": "6601b1d4-89fd-428e-8d99-2d4ee1f8b3b4"
      },
      "outputs": [],
      "source": [
        "!ls '/content/drive/MyDrive/data_structure/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3yLAsfck-Ev",
        "outputId": "07c41ba2-4b85-4886-e13e-a89c48de5bc4"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import shutil\n",
        "\n",
        "source_directory = '/content/'\n",
        "destination_directory = '/content/drive/MyDrive/data_structure/'\n",
        "\n",
        "# Находим первый файл .txt в папке /content/\n",
        "txt_files = glob.glob(os.path.join(source_directory, '*.txt'))\n",
        "\n",
        "if txt_files:\n",
        "    # Берем только первый файл\n",
        "    file = txt_files[0]\n",
        "    destination_path = os.path.join(destination_directory, os.path.basename(file))\n",
        "\n",
        "    # Перемещаем файл\n",
        "    shutil.move(file, destination_path)\n",
        "    print(f'Файл {file} перемещен в {destination_path}')\n",
        "else:\n",
        "    print('Файлы .txt не найдены в директории /content/')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZzv59ZuqdkQ"
      },
      "source": [
        "Выводим текст, который получился"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xo0Ff4nbxzGf",
        "outputId": "1309223e-bc45-44f7-a648-66003e663cf7"
      },
      "outputs": [],
      "source": [
        "# Путь к файлу на Google Драйве\n",
        "\n",
        "file_path = \"/content/drive/MyDrive/data_structure/The AI revolution - Google's developers on the future of artificial intelligence _ 60 Minutes-880TBXMuzmk.txt\"\n",
        "\n",
        "# Чтение и вывод содержимого файла\n",
        "try:\n",
        "    with open(file_path, 'r') as file:\n",
        "        content = file.read()\n",
        "        print(content)\n",
        "except FileNotFoundError:\n",
        "    print(f'Файл не найден: {file_path}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MjgcFf9lYIP-"
      },
      "source": [
        "Итак, мы получили транскрибацию видео по ссылке с ютуб."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EMQ_lrBOak7a",
        "outputId": "5d54fd82-3d8e-425f-8d7a-33f7242608d2"
      },
      "outputs": [],
      "source": [
        "# По запросу вводим ключ OPENAI_API_KEY и не забываем нажать ENTER.\n",
        "\n",
        "import getpass\n",
        "import os\n",
        "import openai\n",
        "openai_key = getpass.getpass(\"OpenAI API Key:\")\n",
        "os.environ[\"OPENAI_API_KEY\"] = openai_key\n",
        "openai.api_key = openai_key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xVtd11wHAGF_"
      },
      "outputs": [],
      "source": [
        "# @title Установка и импорты\n",
        "import shutil\n",
        "from langchain.docstore.document import Document\n",
        "from langchain.llms import OpenAI\n",
        "\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ewWQsHyxC9Qm"
      },
      "outputs": [],
      "source": [
        "# Разбивка на главы, аннотация, краткие выводы, критика материала, вопросы по докладу, ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QuBRAytVvRMn"
      },
      "outputs": [],
      "source": [
        "\n",
        "chunk_size = 8000\n",
        "temperature = 0\n",
        "\n",
        "system = '''Ты гений текста, копирайтинга, писательства, отлично разбирающийся в вопросах искусственного интеллекта. Твоя задача, используя последовательные\n",
        "чанки исходного текста, по всем правилам написать научный студенческий доклад на русском языке.\n",
        "'''\n",
        "user = \"\"\"Пожалуйста, шаг за шагом, объедини все чанки исходного текста в один доклад. Доклад должен содержать только научную и техническую информацию.\n",
        "Убери из доклада всю 'воду', безжалостно удаляй второстепенные пассажи, оставляй только самую суть. Ничего не придумывай от себя.\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WOTNso8SAGLL"
      },
      "outputs": [],
      "source": [
        "# @title Функции\n",
        "# Функция настройки стиля для переноса текста в выводе ячеек\n",
        "# для изменения стиля отображения текста, так чтобы предотвратить переполнение текста за границы ячейки вывода и обеспечить его перенос.\n",
        "def set_text_wrap_css():\n",
        "    css = '''\n",
        "    <style>\n",
        "    pre {\n",
        "        white-space: pre-wrap;\n",
        "    }\n",
        "    </style>\n",
        "    '''\n",
        "    display(HTML(css))\n",
        "\n",
        "get_ipython().events.register('pre_run_cell', set_text_wrap_css)\n",
        "\n",
        "# Функция подсчета количества токенов\n",
        "def num_tokens_from_messages(messages, model='gpt-3.5-turbo-0301'):\n",
        "    try:\n",
        "        encoding = tiktoken.encoding_for_model(model)\n",
        "    except KeyError:\n",
        "        encoding = tiktoken.get_encoding('cl100k_base')\n",
        "\n",
        "    if model in ['gpt-3.5-turbo-0301', 'gpt-3.5-turbo-0613', 'gpt-3.5-turbo-16k', 'gpt-3.5-turbo']:\n",
        "        num_tokens = 0\n",
        "\n",
        "        for message in messages:\n",
        "            num_tokens += 4\n",
        "\n",
        "            for key, value in message.items():\n",
        "                num_tokens += len(encoding.encode(value))\n",
        "\n",
        "                if key == 'name':\n",
        "                    num_tokens -= 1\n",
        "\n",
        "        num_tokens += 2\n",
        "        return num_tokens\n",
        "\n",
        "    else:\n",
        "        raise NotImplementedError(f'''num_tokens_from_messages() is not presently implemented for model {model}.''')\n",
        "\n",
        "\n",
        "# Функция дробления текста на чанки\n",
        "def split_text(txt_file, chunk_size=chunk_size):\n",
        "    source_chunks = []\n",
        "    splitter = RecursiveCharacterTextSplitter(separators=['\\n', '\\n\\n', '. '], chunk_size=chunk_size, chunk_overlap=0)\n",
        "\n",
        "    for chunk in splitter.split_text(txt_file):\n",
        "        source_chunks.append(Document(page_content=chunk, metadata={}))\n",
        "\n",
        "    print(f'\\n\\nТекст разбит на {len(source_chunks)} чанков.')\n",
        "\n",
        "    return source_chunks\n",
        "\n",
        "\n",
        "# Функция получения ответа от модели\n",
        "def answer_index(system, user, chunk, temp=temperature, model='gpt-3.5-turbo-16k'):\n",
        "\n",
        "    messages = [\n",
        "        {'role': 'system', 'content': system},\n",
        "        {'role': 'user', 'content': user + f'{chunk}'}\n",
        "    ]\n",
        "\n",
        "    completion = openai.ChatCompletion.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=temp\n",
        "    )\n",
        "\n",
        "    # Вывод количества токенов отключен\n",
        "    # print(f'\\n====================\\n\\n{num_tokens_from_messages(messages)} токенов будет использовано на чанк\\n\\n')\n",
        "    answer = completion.choices[0].message.content\n",
        "\n",
        "    return answer\n",
        "\n",
        "\n",
        "def process_one_file(file_path, system, user):\n",
        "    with open(file_path, 'r') as txt_file:\n",
        "        text = txt_file.read()\n",
        "    source_chunks = split_text(text)\n",
        "    processed_text = ''\n",
        "    unprocessed_text = ''\n",
        "\n",
        "    for chunk in source_chunks:\n",
        "        attempt = 0\n",
        "\n",
        "        while attempt < 3:\n",
        "            try:\n",
        "                answer = answer_index(system, user, chunk.page_content)\n",
        "                break  # Успешно получили ответ, выходим из цикла попыток\n",
        "\n",
        "            except Exception as e:\n",
        "                attempt += 1  # Увеличиваем счетчик попыток\n",
        "                print(f'\\n\\nПопытка {attempt} не удалась из-за ошибки: {str(e)}')\n",
        "                time.sleep(10)  # Ожидаем перед следующей попыткой\n",
        "                if attempt == 3:\n",
        "                    answer = ''\n",
        "                    print(f'\\n\\nОбработка элемента {chunk} не удалась после 3 попыток')\n",
        "                    unprocessed_text += f'{chunk}\\n\\n'\n",
        "\n",
        "        processed_text += f'{answer}\\n\\n'  # Добавляем ответ в результат\n",
        "        print(f'{answer}')  # Выводим ответ\n",
        "\n",
        "    return processed_text, unprocessed_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "Gk3PWtxkVDKp",
        "outputId": "5b29d5e5-2674-4e0e-af76-68a31f311331"
      },
      "outputs": [],
      "source": [
        "!ls /content/drive/MyDrive/data_structure/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "FYfY8NUAAGQl",
        "outputId": "006d0f9e-1326-4bf8-b4ee-5a44a76ef60f"
      },
      "outputs": [],
      "source": [
        "# @title Формируем текст доклада\n",
        "file_path = \"/content/drive/MyDrive/data_structure/The AI revolution - Google's developers on the future of artificial intelligence _ 60 Minutes-880TBXMuzmk.txt\"\n",
        "\n",
        "# Вызываем функцию обработки для этого файла\n",
        "processed_text, unprocessed_text = process_one_file(file_path, system, user)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
